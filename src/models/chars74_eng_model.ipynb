{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "chars74_eng_model.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "zExvRqtrVqyh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This file contains code for my transfer-learning attempt. I use data for English handwriting publicly available at http://www.ee.surrey.ac.uk/CVSSP/demos/chars74k/. I build a CNN to recongize these characters and then save the model to disk. The transfered model built here didn't transfer well to F.G's handwriting character tiles, and so I abandoned this approach."
      ]
    },
    {
      "metadata": {
        "id": "S1qKARWlWcxF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Imports"
      ]
    },
    {
      "metadata": {
        "id": "c9UHcZiOVqE3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import keras\n",
        "from skimage.io import imread\n",
        "from skimage.transform import resize\n",
        "from matplotlib import pyplot as plt\n",
        "from random import seed, sample\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.grid_search import GridSearchCV\n",
        "from pprint import pprint\n",
        "from sklearn.metrics import accuracy_score\n",
        "from random import randint\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Mr-Nb8PNWgXX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Untar the EnglishHnd.tgz file from http://www.ee.surrey.ac.uk/CVSSP/demos/chars74k/"
      ]
    },
    {
      "metadata": {
        "id": "EhZ8c-SN0f8l",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!tar -xvf EnglishHnd.tgz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eCirb-9IWnQe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Read the images and resize to 20 X 20 pixels. The character classes are - A-Z, a-z and 0-9. I map the upper and lower case letters to the same class, and hence have 36 classes in total."
      ]
    },
    {
      "metadata": {
        "id": "-jbhEOkx7wAj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "rootDir = './English/Hnd/Img'\n",
        "n_images = 6420\n",
        "images = np.zeros((n_images,) + (20, 20))\n",
        "\n",
        "labels = []\n",
        "\n",
        "j = 0\n",
        "for dirName, subdirList, fileList in os.walk(rootDir):\n",
        "    i = 0\n",
        "    if 'Sample' in dirName:\n",
        "        label = int(dirName[-2:])\n",
        "        if label > 36:\n",
        "            label -= 26\n",
        "    for fname in fileList:\n",
        "        if 'png' not in fname:\n",
        "            continue\n",
        "        full_path = os.path.join(dirName, fname)\n",
        "        images[j] = resize(imread(full_path, as_grey=True), (20, 20)) \n",
        "        labels.append(label)\n",
        "        j += 1\n",
        "        i += 1\n",
        "images = images[:len(labels)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vk37lsFHWzwz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Use a 80% - 20% split of training set - test set split"
      ]
    },
    {
      "metadata": {
        "id": "eT9ad8Hwo9D0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "08b34cc3-bfc4-493a-f327-6de18c6af999"
      },
      "cell_type": "code",
      "source": [
        "k = sample(range(len(images)), len(images))\n",
        "im_shuf = images[k]\n",
        "labels_shuf = np.array(labels)[k]\n",
        "    \n",
        "ocr = {\n",
        "    'images': im_shuf,\n",
        "    'data': im_shuf.reshape((im_shuf.shape[0], -1)),\n",
        "    'target': labels_shuf\n",
        "}\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(im_shuf, labels_shuf, random_state=2, train_size=0.8)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "XDYNeH78h3fS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2091
        },
        "outputId": "af82e080-c460-460c-d74c-ef7180eededd"
      },
      "cell_type": "code",
      "source": [
        "num_classes = 37 # Class 0 is ignored\n",
        "batch_size = 128\n",
        "\n",
        "X_train = x_train.reshape(x_train.shape[0], 20, 20 , 1).astype('float32')\n",
        "X_test = x_test.reshape(x_test.shape[0], 20, 20 , 1).astype('float32')\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, kernel_size=(5, 5), activation='relu', input_shape=(20, 20, 1)))\n",
        "\n",
        "model.add(Conv2D(64, (5, 5), activation='relu'))\n",
        "\n",
        "model.add(Conv2D(128, (5, 5), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.summary()\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.Adadelta(),\n",
        "              metrics=['accuracy'])\n",
        "model.fit(X_train, y_train, batch_size=batch_size,\n",
        "                        nb_epoch=50,\n",
        "                        verbose=1)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 16, 16, 32)        832       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 12, 12, 64)        51264     \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 8, 8, 128)         204928    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 2048)              0         \n",
            "=================================================================\n",
            "Total params: 257,024\n",
            "Trainable params: 257,024\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/models.py:981: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "2728/2728 [==============================] - 10s 4ms/step - loss: 3.6034 - acc: 0.0286\n",
            "Epoch 2/50\n",
            "2728/2728 [==============================] - 10s 4ms/step - loss: 3.5687 - acc: 0.0385\n",
            "Epoch 3/50\n",
            "2728/2728 [==============================] - 10s 4ms/step - loss: 3.5130 - acc: 0.0590\n",
            "Epoch 4/50\n",
            "2728/2728 [==============================] - 10s 4ms/step - loss: 3.3333 - acc: 0.1001\n",
            "Epoch 5/50\n",
            "2728/2728 [==============================] - 10s 4ms/step - loss: 3.0886 - acc: 0.1503\n",
            "Epoch 6/50\n",
            "2728/2728 [==============================] - 10s 4ms/step - loss: 2.7932 - acc: 0.2163\n",
            "Epoch 7/50\n",
            "2728/2728 [==============================] - 10s 4ms/step - loss: 2.5532 - acc: 0.2680\n",
            "Epoch 8/50\n",
            "2728/2728 [==============================] - 10s 4ms/step - loss: 2.2825 - acc: 0.3457\n",
            "Epoch 9/50\n",
            "2728/2728 [==============================] - 10s 4ms/step - loss: 2.0707 - acc: 0.3970\n",
            "Epoch 10/50\n",
            "2728/2728 [==============================] - 10s 4ms/step - loss: 1.9144 - acc: 0.4326\n",
            "Epoch 11/50\n",
            "2728/2728 [==============================] - 10s 4ms/step - loss: 1.7393 - acc: 0.4773\n",
            "Epoch 12/50\n",
            "2728/2728 [==============================] - 10s 4ms/step - loss: 1.6778 - acc: 0.5084\n",
            "Epoch 13/50\n",
            "2728/2728 [==============================] - 10s 4ms/step - loss: 1.4908 - acc: 0.5513\n",
            "Epoch 14/50\n",
            "2728/2728 [==============================] - 10s 4ms/step - loss: 1.3869 - acc: 0.5748\n",
            "Epoch 15/50\n",
            "2728/2728 [==============================] - 10s 4ms/step - loss: 1.2935 - acc: 0.6015\n",
            "Epoch 16/50\n",
            "2728/2728 [==============================] - 10s 4ms/step - loss: 1.2355 - acc: 0.6096\n",
            "Epoch 17/50\n",
            "2728/2728 [==============================] - 10s 4ms/step - loss: 1.1753 - acc: 0.6265\n",
            "Epoch 18/50\n",
            "2728/2728 [==============================] - 10s 4ms/step - loss: 1.0783 - acc: 0.6639\n",
            "Epoch 19/50\n",
            "2728/2728 [==============================] - 10s 4ms/step - loss: 1.0212 - acc: 0.6771\n",
            "Epoch 20/50\n",
            "2728/2728 [==============================] - 10s 4ms/step - loss: 0.9605 - acc: 0.6939\n",
            "Epoch 21/50\n",
            "2728/2728 [==============================] - 11s 4ms/step - loss: 0.9303 - acc: 0.6961\n",
            "Epoch 22/50\n",
            "2728/2728 [==============================] - 10s 4ms/step - loss: 0.8732 - acc: 0.7148\n",
            "Epoch 23/50\n",
            "2728/2728 [==============================] - 10s 4ms/step - loss: 0.8445 - acc: 0.7273\n",
            "Epoch 24/50\n",
            "2728/2728 [==============================] - 10s 4ms/step - loss: 0.7503 - acc: 0.7588\n",
            "Epoch 25/50\n",
            "2728/2728 [==============================] - 10s 4ms/step - loss: 0.7418 - acc: 0.7592\n",
            "Epoch 26/50\n",
            "2728/2728 [==============================] - 10s 4ms/step - loss: 0.7121 - acc: 0.7603\n",
            "Epoch 27/50\n",
            "2728/2728 [==============================] - 10s 4ms/step - loss: 0.6956 - acc: 0.7621\n",
            "Epoch 28/50\n",
            "2728/2728 [==============================] - 10s 4ms/step - loss: 0.6771 - acc: 0.7782\n",
            "Epoch 29/50\n",
            "2728/2728 [==============================] - 10s 4ms/step - loss: 0.6164 - acc: 0.7977\n",
            "Epoch 30/50\n",
            "2728/2728 [==============================] - 10s 4ms/step - loss: 0.6149 - acc: 0.7933\n",
            "Epoch 31/50\n",
            "2728/2728 [==============================] - 10s 4ms/step - loss: 0.5736 - acc: 0.8035\n",
            "Epoch 32/50\n",
            "2728/2728 [==============================] - 10s 4ms/step - loss: 0.5713 - acc: 0.8083\n",
            "Epoch 33/50\n",
            "2728/2728 [==============================] - 10s 4ms/step - loss: 0.5577 - acc: 0.8087\n",
            "Epoch 34/50\n",
            "2728/2728 [==============================] - 10s 4ms/step - loss: 0.5176 - acc: 0.8189\n",
            "Epoch 35/50\n",
            "2728/2728 [==============================] - 10s 4ms/step - loss: 0.5054 - acc: 0.8277\n",
            "Epoch 36/50\n",
            "2728/2728 [==============================] - 10s 4ms/step - loss: 0.4673 - acc: 0.8409\n",
            "Epoch 37/50\n",
            "2728/2728 [==============================] - 10s 4ms/step - loss: 0.4778 - acc: 0.8336\n",
            "Epoch 38/50\n",
            "2728/2728 [==============================] - 10s 4ms/step - loss: 0.4538 - acc: 0.8493\n",
            "Epoch 39/50\n",
            "2728/2728 [==============================] - 10s 4ms/step - loss: 0.4176 - acc: 0.8596\n",
            "Epoch 40/50\n",
            "2728/2728 [==============================] - 10s 4ms/step - loss: 0.4022 - acc: 0.8618\n",
            "Epoch 41/50\n",
            "2728/2728 [==============================] - 10s 4ms/step - loss: 0.4258 - acc: 0.8537\n",
            "Epoch 42/50\n",
            "2728/2728 [==============================] - 10s 4ms/step - loss: 0.4102 - acc: 0.8651\n",
            "Epoch 43/50\n",
            "2728/2728 [==============================] - 10s 4ms/step - loss: 0.3597 - acc: 0.8757\n",
            "Epoch 44/50\n",
            "2728/2728 [==============================] - 10s 4ms/step - loss: 0.3818 - acc: 0.8713\n",
            "Epoch 45/50\n",
            "2728/2728 [==============================] - 10s 4ms/step - loss: 0.4039 - acc: 0.8592\n",
            "Epoch 46/50\n",
            "2728/2728 [==============================] - 10s 4ms/step - loss: 0.3667 - acc: 0.8688\n",
            "Epoch 47/50\n",
            "2728/2728 [==============================] - 10s 4ms/step - loss: 0.3529 - acc: 0.8827\n",
            "Epoch 48/50\n",
            "2728/2728 [==============================] - 10s 4ms/step - loss: 0.3171 - acc: 0.8893\n",
            "Epoch 49/50\n",
            "2728/2728 [==============================] - 10s 4ms/step - loss: 0.3343 - acc: 0.8860\n",
            "Epoch 50/50\n",
            "2728/2728 [==============================] - 10s 4ms/step - loss: 0.3594 - acc: 0.8812\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3bb0ecfeb8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "R6nGdFRySrEN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "846e7550-92e7-4319-f9c1-0fc2312c935e"
      },
      "cell_type": "code",
      "source": [
        "scores = model.evaluate(X_test, y_test, verbose = 10 )\n",
        "print ( scores )"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.2553904509264702, 0.7023460407061312]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "C8WLds0kgymR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fa4ac7f7-69d1-44a4-8372-94e072bfd540"
      },
      "cell_type": "code",
      "source": [
        "# serialize model to JSON\n",
        "model_json = model.to_json()\n",
        "with open(\"model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "# serialize weights to HDF5\n",
        "model.save_weights(\"model.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "doaZfOi1xklu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ynew = model.predict_classes(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}