{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "high_freq_model.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "FcCAH06vXc8W",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This file contains the baseline model and the final model I built on F.G.'s handwritten journal image cropped tiles. The main file for the project. Also, in this file I select the most frequent 7 classes and the model is built to predict these classes. I used the top 7 most frequent since they have at least 300 labeled examples.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "Ue_c4pryXcE9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import keras\n",
        "from keras.models import model_from_json\n",
        "from skimage.transform import resize\n",
        "from skimage.io import imread\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from random import seed, sample\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n",
        "from collections import Counter\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.grid_search import GridSearchCV\n",
        "from pprint import pprint\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "19VPbQJ9Xw2E",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "ld.tar contains the tarred labeled_data directory from https://github.com/Vinaymy/wtf/tree/master/data/labeled_data"
      ]
    },
    {
      "metadata": {
        "id": "7-yrNPsEncs-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!tar -xvf ld.tar"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Pr8tpnSoYWYZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Load up the cropped labeled images and map them to class labels. "
      ]
    },
    {
      "metadata": {
        "id": "zcTAutBXZOg7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "NdiOZ8adnqhD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "rootDir = './labeled_data'\n",
        "n_images = 10000\n",
        "images = np.zeros((n_images,) + (20, 20))\n",
        "minimum_number_of_examples = 300 # I came up with this after inspecting the distribution of frequencies of the labeled classes. \n",
        "# I decided that images with fewer than examples is too few to try predict.\n",
        "\n",
        "labels = []\n",
        "lab = {\n",
        "    '0': 1, '1': 2, '2': 3, '3':4, '4':5, '5':6, '6':7, '7':8, '8':9, '9':10,\n",
        "    'A': 11, 'B': 12, 'C': 13, 'D': 14, 'E': 15, 'F': 16, 'G': 17, 'H': 18, 'I': 19, 'J': 20, 'K': 21, 'L': 22, 'M': 23, \n",
        "    'N': 24, 'O': 25, 'P': 26, 'Q': 27, 'R': 28, 'S': 29, 'T': 30, 'U': 31, 'V': 32, 'W': 33, 'X': 34, 'Y': 35, 'Z': 36,\n",
        "    'a': 11, 'b': 12, 'c': 13, 'd': 14, 'e': 15, 'f': 16, 'g': 17, 'h': 18, 'i': 19, 'j': 20, 'k': 21, 'l': 22, 'm': 23, \n",
        "    'n': 24, 'o': 25, 'p': 26, 'q': 27, 'r': 28, 's': 29, 't': 30, 'u': 31, 'v': 32, 'w': 33, 'x': 34, 'y': 35, 'z': 36\n",
        "}\n",
        "j = 0\n",
        "ct = {}\n",
        "for dirName, subdirList, fileList in os.walk(rootDir):\n",
        "    i = 0\n",
        "    for fname in fileList:\n",
        "        if 'png' not in fname or fname[:3] !='IMG':\n",
        "            continue\n",
        "        full_path = os.path.join(dirName, fname)\n",
        "        \n",
        "        if dirName[-1] in ['E', 'e', 'A', 'a', 'T', 't', 'S', 's', 'D', 'd', 'N', 'n', 'O', 'o'] \\\n",
        "        and dirName[-2] == '/' and ct.get(dirName[-1].lower(), 0) < minimum_number_of_examples:\n",
        "            ct[dirName[-1].lower()] = ct.get(dirName[-1].lower(), 0) + 1\n",
        "        else:\n",
        "            continue\n",
        "        \n",
        "        # Resize to 20 X 20\n",
        "        images[j] = resize(imread(full_path, as_grey=True), (20, 20)) \n",
        "        labels.append(lab[dirName[-1]])\n",
        "        j += 1\n",
        "        i += 1\n",
        "images = images[:len(labels)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H6H6juvzYfuf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In the next part, I inspect"
      ]
    },
    {
      "metadata": {
        "id": "_oyuOcnMPUva",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "count = Counter(labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G21jGSKpQPL4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "25eaf289-47ec-4365-c554-9a5563f2ec5a"
      },
      "cell_type": "code",
      "source": [
        "count.most_common() # 7 labels of and balanced since I picked 300 of each"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(29, 300), (15, 300), (14, 300), (30, 300), (24, 300), (25, 300), (11, 300)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "metadata": {
        "id": "bf8QPhaFydh_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "len(labels), images[0], labels[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "V28ky1hIyoOu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a5f6b4b4-9c58-461e-c714-74b37efd218a"
      },
      "cell_type": "code",
      "source": [
        "np.unique(labels)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([11, 14, 15, 24, 25, 29, 30])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "metadata": {
        "id": "BRFcE3m9lJxs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "uniques, ids = np.unique(labels, return_inverse=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XGGhuwyuZemS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Perform 80% - 20% split of examples. Then we'll have 240 examples of each character in training set and 60 examples of each in test set"
      ]
    },
    {
      "metadata": {
        "id": "HZQrOO_l5Hqm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "346c40fc-b7ad-4808-e2f6-3c67a2a0b1c5"
      },
      "cell_type": "code",
      "source": [
        "k = sample(range(len(images)), len(images))\n",
        "im_shuf = images[k]\n",
        "labels_shuf = np.array(labels)[k]\n",
        "    \n",
        "ocr = {\n",
        "    'images': im_shuf,\n",
        "    'data': im_shuf.reshape((im_shuf.shape[0], -1)),\n",
        "    'target': labels_shuf\n",
        "}\n",
        "x_train, x_test, y_train, y_test = train_test_split(im_shuf, labels_shuf, random_state=2, train_size=0.8)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "8iufD5956Hkm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b06ce2b0-3e64-4f36-ba32-719708d8b530"
      },
      "cell_type": "code",
      "source": [
        "y_train.shape"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1680,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "metadata": {
        "id": "igy_5RLsZvFs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Build a baseline model and record its accuracy on the test set for reference. I build a linear SVM with grid search on hyperparameter C. I get an accuracy of 0.23 on the test set for the baseline model"
      ]
    },
    {
      "metadata": {
        "id": "GEOyGfYS3DTK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1802
        },
        "outputId": "24943d98-0ef9-49db-fbfb-3f5ef0015bf7"
      },
      "cell_type": "code",
      "source": [
        "base_model = LinearSVC()\n",
        "param_grid = {'C':  list(np.arange(0.1,1.5,0.1))}\n",
        "\n",
        "gs = GridSearchCV(base_model, param_grid, n_jobs=-1, cv=3, verbose=4)\n",
        "x_train_resh = x_train.reshape((x_train.shape[0], -1))\n",
        "x_test_resh = x_test.reshape((x_test.shape[0], -1))\n",
        "gs.fit(x_train_resh, y_train)\n",
        "pprint(sorted(gs.grid_scores_, key=lambda x: -x.mean_validation_score))\n",
        "\n",
        "y_pred = gs.predict(x_test_resh)\n",
        "print ('Test set shape: ', x_test_resh.shape)\n",
        "print ('Target shape: ', y_test.shape)\n",
        "print ('Accuracy on train set: ', accuracy_score(y_train, gs.predict(x_train_resh)))\n",
        "print ('Accuracy on test set: ', accuracy_score(y_test, y_pred))"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 14 candidates, totalling 42 fits\n",
            "[CV] C=0.1 ...........................................................\n",
            "[CV] C=0.1 ...........................................................\n",
            "[CV] .................................. C=0.1, score=0.225577 -   6.3s\n",
            "[CV] C=0.1 ...........................................................\n",
            "[CV] .................................. C=0.1, score=0.210714 -   7.0s\n",
            "[CV] C=0.2 ...........................................................\n",
            "[CV] .................................. C=0.1, score=0.222621 -   8.0s\n",
            "[CV] C=0.2 ...........................................................\n",
            "[CV] .................................. C=0.2, score=0.211368 -  10.2s\n",
            "[CV] C=0.2 ...........................................................\n",
            "[CV] .................................. C=0.2, score=0.207143 -  10.2s\n",
            "[CV] C=0.30000000000000004 ...........................................\n",
            "[CV] .................................. C=0.2, score=0.211849 -  10.4s\n",
            "[CV] C=0.30000000000000004 ...........................................\n",
            "[CV] .................. C=0.30000000000000004, score=0.213144 -  10.0s\n",
            "[CV] C=0.30000000000000004 ...........................................\n",
            "[CV] .................. C=0.30000000000000004, score=0.200000 -   9.9s\n",
            "[CV] C=0.4 ...........................................................\n",
            "[CV] .................. C=0.30000000000000004, score=0.206463 -   9.9s\n",
            "[CV] C=0.4 ...........................................................\n",
            "[CV] .................................. C=0.4, score=0.211368 -  10.1s\n",
            "[CV] C=0.4 ...........................................................\n",
            "[CV] .................................. C=0.4, score=0.201786 -  10.1s\n",
            "[CV] C=0.5 ...........................................................\n",
            "[CV] .................................. C=0.4, score=0.202873 -  10.1s\n",
            "[CV] C=0.5 ...........................................................\n",
            "[CV] .................................. C=0.5, score=0.204263 -  10.2s\n",
            "[CV] C=0.5 ...........................................................\n",
            "[CV] .................................. C=0.5, score=0.198214 -  10.2s\n",
            "[CV] C=0.6 ...........................................................\n",
            "[CV] .................................. C=0.5, score=0.201077 -   9.8s\n",
            "[CV] C=0.6 ...........................................................\n",
            "[CV] .................................. C=0.6, score=0.204263 -   9.7s\n",
            "[CV] C=0.6 ...........................................................\n",
            "[CV] .................................. C=0.6, score=0.192857 -   9.7s\n",
            "[CV] C=0.7000000000000001 ............................................\n",
            "[CV] .................................. C=0.6, score=0.202873 -   9.7s\n",
            "[CV] C=0.7000000000000001 ............................................\n",
            "[CV] ................... C=0.7000000000000001, score=0.204263 -   9.7s\n",
            "[CV] C=0.7000000000000001 ............................................\n",
            "[CV] ................... C=0.7000000000000001, score=0.189286 -   9.9s\n",
            "[CV] C=0.8 ...........................................................\n",
            "[CV] ................... C=0.7000000000000001, score=0.195691 -   9.7s\n",
            "[CV] C=0.8 ...........................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:  1.7min\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] .................................. C=0.8, score=0.206039 -   9.9s\n",
            "[CV] C=0.8 ...........................................................\n",
            "[CV] .................................. C=0.8, score=0.196429 -   9.7s\n",
            "[CV] C=0.9 ...........................................................\n",
            "[CV] .................................. C=0.8, score=0.197487 -   9.8s\n",
            "[CV] C=0.9 ...........................................................\n",
            "[CV] .................................. C=0.9, score=0.204263 -   9.9s\n",
            "[CV] C=0.9 ...........................................................\n",
            "[CV] .................................. C=0.9, score=0.192857 -  10.0s\n",
            "[CV] C=1.0 ...........................................................\n",
            "[CV] .................................. C=0.9, score=0.201077 -   9.9s\n",
            "[CV] C=1.0 ...........................................................\n",
            "[CV] .................................. C=1.0, score=0.211368 -   9.8s\n",
            "[CV] C=1.0 ...........................................................\n",
            "[CV] .................................. C=1.0, score=0.200000 -   9.7s\n",
            "[CV] C=1.1 ...........................................................\n",
            "[CV] .................................. C=1.0, score=0.199282 -   9.8s\n",
            "[CV] C=1.1 ...........................................................\n",
            "[CV] .................................. C=1.1, score=0.204263 -   9.8s\n",
            "[CV] C=1.1 ...........................................................\n",
            "[CV] .................................. C=1.1, score=0.200000 -   9.9s\n",
            "[CV] C=1.2000000000000002 ............................................\n",
            "[CV] .................................. C=1.1, score=0.208259 -   9.5s\n",
            "[CV] C=1.2000000000000002 ............................................\n",
            "[CV] ................... C=1.2000000000000002, score=0.202487 -   9.6s\n",
            "[CV] C=1.2000000000000002 ............................................\n",
            "[CV] ................... C=1.2000000000000002, score=0.189286 -   9.3s\n",
            "[CV] C=1.3000000000000003 ............................................\n",
            "[CV] ................... C=1.2000000000000002, score=0.188510 -   9.5s\n",
            "[CV] C=1.3000000000000003 ............................................\n",
            "[CV] ................... C=1.3000000000000003, score=0.193606 -   9.6s\n",
            "[CV] C=1.3000000000000003 ............................................\n",
            "[CV] ................... C=1.3000000000000003, score=0.185714 -   9.9s\n",
            "[CV] C=1.4000000000000001 ............................................\n",
            "[CV] ................... C=1.3000000000000003, score=0.201077 -   9.4s\n",
            "[CV] C=1.4000000000000001 ............................................\n",
            "[CV] ................... C=1.4000000000000001, score=0.202487 -   9.6s\n",
            "[CV] C=1.4000000000000001 ............................................\n",
            "[CV] ................... C=1.4000000000000001, score=0.205357 -   9.4s\n",
            "[CV] ................... C=1.4000000000000001, score=0.170557 -   7.9s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  42 out of  42 | elapsed:  3.4min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[mean: 0.21964, std: 0.00642, params: {'C': 0.1},\n",
            " mean: 0.21012, std: 0.00211, params: {'C': 0.2},\n",
            " mean: 0.20655, std: 0.00537, params: {'C': 0.30000000000000004},\n",
            " mean: 0.20536, std: 0.00428, params: {'C': 0.4},\n",
            " mean: 0.20417, std: 0.00337, params: {'C': 1.1},\n",
            " mean: 0.20357, std: 0.00554, params: {'C': 1.0},\n",
            " mean: 0.20119, std: 0.00247, params: {'C': 0.5},\n",
            " mean: 0.20000, std: 0.00508, params: {'C': 0.6},\n",
            " mean: 0.20000, std: 0.00430, params: {'C': 0.8},\n",
            " mean: 0.19940, std: 0.00481, params: {'C': 0.9},\n",
            " mean: 0.19643, std: 0.00614, params: {'C': 0.7000000000000001},\n",
            " mean: 0.19345, std: 0.00641, params: {'C': 1.2000000000000002},\n",
            " mean: 0.19345, std: 0.00627, params: {'C': 1.3000000000000003},\n",
            " mean: 0.19286, std: 0.01577, params: {'C': 1.4000000000000001}]\n",
            "Test set shape:  (420, 400)\n",
            "Target shape:  (420,)\n",
            "Accuracy on train set:  0.4720238095238095\n",
            "Accuracy on test set:  0.23333333333333334\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Bd-2Eq3LaCuN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Next I build a CNN for the final model"
      ]
    },
    {
      "metadata": {
        "id": "byJKrFCrlak_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "num_classes = len(uniques)+1\n",
        "batch_size = 128\n",
        "\n",
        "X_train = x_train.reshape(x_train.shape[0], 20, 20 , 1).astype('float32')\n",
        "X_test = x_test.reshape(x_test.shape[0], 20, 20 , 1).astype('float32')\n",
        "\n",
        "uniques, ids_tr = np.unique(y_train, return_inverse=True)\n",
        "uniques, ids_te = np.unique(y_test, return_inverse=True)\n",
        "\n",
        "Y_train = to_categorical(ids_tr, num_classes)\n",
        "Y_test = to_categorical(ids_te, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BKQjZ-EYaLMT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Specify the model architecture and train it and test it. I get a training accuracy of 0.941 and a test accuracy of 0.807. 70 epochs and batch size of 128 arrived through trial and error"
      ]
    },
    {
      "metadata": {
        "id": "4pVBfBlp5FDQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2873
        },
        "outputId": "c5f46f2f-615c-4423-e168-af1573a99d40"
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, kernel_size=(5, 5), activation='relu', input_shape=(20, 20, 1)))\n",
        "\n",
        "model.add(Conv2D(64, (5, 5), activation='relu'))\n",
        "\n",
        "model.add(Conv2D(128, (5, 5), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.Adadelta(),\n",
        "              metrics=['accuracy'])\n",
        "model.fit(X_train, Y_train, batch_size=batch_size,\n",
        "                        nb_epoch=70,\n",
        "                        verbose=1)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_13 (Conv2D)           (None, 16, 16, 32)        832       \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 12, 12, 64)        51264     \n",
            "_________________________________________________________________\n",
            "conv2d_15 (Conv2D)           (None, 8, 8, 128)         204928    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 128)               262272    \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 8)                 1032      \n",
            "=================================================================\n",
            "Total params: 520,328\n",
            "Trainable params: 520,328\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/models.py:981: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/70\n",
            "1680/1680 [==============================] - 7s 4ms/step - loss: 2.0362 - acc: 0.1452\n",
            "Epoch 2/70\n",
            "1680/1680 [==============================] - 6s 4ms/step - loss: 1.9984 - acc: 0.1435\n",
            "Epoch 3/70\n",
            "1680/1680 [==============================] - 6s 4ms/step - loss: 1.9952 - acc: 0.1321\n",
            "Epoch 4/70\n",
            "1680/1680 [==============================] - 6s 4ms/step - loss: 1.9934 - acc: 0.1315\n",
            "Epoch 5/70\n",
            "1680/1680 [==============================] - 6s 4ms/step - loss: 1.9817 - acc: 0.1446\n",
            "Epoch 6/70\n",
            "1680/1680 [==============================] - 6s 4ms/step - loss: 1.9751 - acc: 0.1631\n",
            "Epoch 7/70\n",
            "1680/1680 [==============================] - 6s 4ms/step - loss: 1.9710 - acc: 0.1488\n",
            "Epoch 8/70\n",
            "1680/1680 [==============================] - 6s 4ms/step - loss: 1.9699 - acc: 0.1375\n",
            "Epoch 9/70\n",
            "1680/1680 [==============================] - 6s 4ms/step - loss: 1.9642 - acc: 0.1702\n",
            "Epoch 10/70\n",
            "1680/1680 [==============================] - 6s 4ms/step - loss: 1.9677 - acc: 0.1506\n",
            "Epoch 11/70\n",
            "1680/1680 [==============================] - 6s 4ms/step - loss: 1.9568 - acc: 0.1500\n",
            "Epoch 12/70\n",
            "1680/1680 [==============================] - 6s 4ms/step - loss: 1.9454 - acc: 0.1732\n",
            "Epoch 13/70\n",
            "1680/1680 [==============================] - 6s 4ms/step - loss: 1.9165 - acc: 0.2024\n",
            "Epoch 14/70\n",
            "1680/1680 [==============================] - 6s 4ms/step - loss: 1.9229 - acc: 0.2054\n",
            "Epoch 15/70\n",
            "1680/1680 [==============================] - 6s 4ms/step - loss: 1.8941 - acc: 0.2232\n",
            "Epoch 16/70\n",
            "1680/1680 [==============================] - 6s 4ms/step - loss: 1.8771 - acc: 0.2333\n",
            "Epoch 17/70\n",
            "1680/1680 [==============================] - 6s 4ms/step - loss: 1.8431 - acc: 0.2589\n",
            "Epoch 18/70\n",
            "1680/1680 [==============================] - 6s 4ms/step - loss: 1.8284 - acc: 0.2702\n",
            "Epoch 19/70\n",
            "1680/1680 [==============================] - 6s 4ms/step - loss: 1.7839 - acc: 0.3107\n",
            "Epoch 20/70\n",
            "1680/1680 [==============================] - 6s 4ms/step - loss: 1.7281 - acc: 0.3363\n",
            "Epoch 21/70\n",
            "1680/1680 [==============================] - 6s 4ms/step - loss: 1.7056 - acc: 0.3333\n",
            "Epoch 22/70\n",
            "1680/1680 [==============================] - 6s 4ms/step - loss: 1.5863 - acc: 0.3952\n",
            "Epoch 23/70\n",
            "1680/1680 [==============================] - 6s 4ms/step - loss: 1.4998 - acc: 0.4202\n",
            "Epoch 24/70\n",
            "1680/1680 [==============================] - 6s 4ms/step - loss: 1.5791 - acc: 0.4018\n",
            "Epoch 25/70\n",
            "1680/1680 [==============================] - 6s 4ms/step - loss: 1.4257 - acc: 0.4768\n",
            "Epoch 26/70\n",
            "1680/1680 [==============================] - 6s 4ms/step - loss: 1.3139 - acc: 0.5190\n",
            "Epoch 27/70\n",
            "1680/1680 [==============================] - 6s 4ms/step - loss: 1.2996 - acc: 0.5196\n",
            "Epoch 28/70\n",
            "1680/1680 [==============================] - 6s 4ms/step - loss: 1.1636 - acc: 0.5750\n",
            "Epoch 29/70\n",
            "1680/1680 [==============================] - 6s 4ms/step - loss: 1.1561 - acc: 0.5732\n",
            "Epoch 30/70\n",
            "1680/1680 [==============================] - 6s 4ms/step - loss: 1.1730 - acc: 0.5744\n",
            "Epoch 31/70\n",
            "1680/1680 [==============================] - 6s 4ms/step - loss: 1.0475 - acc: 0.6315\n",
            "Epoch 32/70\n",
            "1680/1680 [==============================] - 6s 4ms/step - loss: 0.9527 - acc: 0.6655\n",
            "Epoch 33/70\n",
            "1680/1680 [==============================] - 6s 4ms/step - loss: 0.9688 - acc: 0.6696\n",
            "Epoch 34/70\n",
            "1680/1680 [==============================] - 6s 4ms/step - loss: 0.8650 - acc: 0.7006\n",
            "Epoch 35/70\n",
            "1680/1680 [==============================] - 6s 4ms/step - loss: 0.8208 - acc: 0.7060\n",
            "Epoch 36/70\n",
            "1680/1680 [==============================] - 6s 4ms/step - loss: 0.7953 - acc: 0.7185\n",
            "Epoch 37/70\n",
            "1680/1680 [==============================] - 6s 4ms/step - loss: 0.7202 - acc: 0.7554\n",
            "Epoch 38/70\n",
            "1680/1680 [==============================] - 6s 4ms/step - loss: 0.7458 - acc: 0.7339\n",
            "Epoch 39/70\n",
            "1680/1680 [==============================] - 6s 4ms/step - loss: 0.6562 - acc: 0.7613\n",
            "Epoch 40/70\n",
            "1680/1680 [==============================] - 6s 4ms/step - loss: 0.6404 - acc: 0.7702\n",
            "Epoch 41/70\n",
            "1680/1680 [==============================] - 6s 4ms/step - loss: 0.6244 - acc: 0.7881\n",
            "Epoch 42/70\n",
            "1680/1680 [==============================] - 6s 4ms/step - loss: 0.5880 - acc: 0.7917\n",
            "Epoch 43/70\n",
            "1680/1680 [==============================] - 6s 4ms/step - loss: 0.5325 - acc: 0.8137\n",
            "Epoch 44/70\n",
            "1680/1680 [==============================] - 6s 4ms/step - loss: 0.5210 - acc: 0.8179\n",
            "Epoch 45/70\n",
            "1680/1680 [==============================] - 6s 4ms/step - loss: 0.4395 - acc: 0.8554\n",
            "Epoch 46/70\n",
            "1680/1680 [==============================] - 6s 4ms/step - loss: 0.4861 - acc: 0.8357\n",
            "Epoch 47/70\n",
            "1680/1680 [==============================] - 6s 4ms/step - loss: 0.5095 - acc: 0.8202\n",
            "Epoch 48/70\n",
            "1680/1680 [==============================] - 6s 4ms/step - loss: 0.3588 - acc: 0.8833\n",
            "Epoch 49/70\n",
            "1680/1680 [==============================] - 6s 4ms/step - loss: 0.3873 - acc: 0.8661\n",
            "Epoch 50/70\n",
            "1680/1680 [==============================] - 6s 4ms/step - loss: 0.4184 - acc: 0.8589\n",
            "Epoch 51/70\n",
            "1680/1680 [==============================] - 6s 4ms/step - loss: 0.3702 - acc: 0.8732\n",
            "Epoch 52/70\n",
            "1680/1680 [==============================] - 6s 4ms/step - loss: 0.3789 - acc: 0.8649\n",
            "Epoch 53/70\n",
            "1680/1680 [==============================] - 6s 4ms/step - loss: 0.3262 - acc: 0.8857\n",
            "Epoch 54/70\n",
            "1680/1680 [==============================] - 6s 4ms/step - loss: 0.3088 - acc: 0.8881\n",
            "Epoch 55/70\n",
            "1680/1680 [==============================] - 6s 4ms/step - loss: 0.2892 - acc: 0.9030\n",
            "Epoch 56/70\n",
            "1680/1680 [==============================] - 6s 4ms/step - loss: 0.3217 - acc: 0.8851\n",
            "Epoch 57/70\n",
            "1680/1680 [==============================] - 6s 4ms/step - loss: 0.2878 - acc: 0.9054\n",
            "Epoch 58/70\n",
            "1680/1680 [==============================] - 6s 4ms/step - loss: 0.2791 - acc: 0.9089\n",
            "Epoch 59/70\n",
            "1680/1680 [==============================] - 6s 4ms/step - loss: 0.2720 - acc: 0.9030\n",
            "Epoch 60/70\n",
            "1680/1680 [==============================] - 6s 4ms/step - loss: 0.2385 - acc: 0.9131\n",
            "Epoch 61/70\n",
            "1680/1680 [==============================] - 6s 4ms/step - loss: 0.2681 - acc: 0.9048\n",
            "Epoch 62/70\n",
            "1680/1680 [==============================] - 6s 4ms/step - loss: 0.2248 - acc: 0.9262\n",
            "Epoch 63/70\n",
            "1680/1680 [==============================] - 6s 4ms/step - loss: 0.2099 - acc: 0.9315\n",
            "Epoch 64/70\n",
            "1680/1680 [==============================] - 6s 4ms/step - loss: 0.2341 - acc: 0.9173\n",
            "Epoch 65/70\n",
            "1680/1680 [==============================] - 6s 4ms/step - loss: 0.1825 - acc: 0.9399\n",
            "Epoch 66/70\n",
            "1680/1680 [==============================] - 6s 4ms/step - loss: 0.2010 - acc: 0.9304\n",
            "Epoch 67/70\n",
            "1680/1680 [==============================] - 6s 4ms/step - loss: 0.2576 - acc: 0.9077\n",
            "Epoch 68/70\n",
            "1680/1680 [==============================] - 6s 4ms/step - loss: 0.1843 - acc: 0.9363\n",
            "Epoch 69/70\n",
            "1680/1680 [==============================] - 6s 4ms/step - loss: 0.2522 - acc: 0.9214\n",
            "Epoch 70/70\n",
            "1680/1680 [==============================] - 6s 4ms/step - loss: 0.1712 - acc: 0.9411\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4ad7e29860>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "metadata": {
        "id": "FogihFfB7dCI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "95375fb7-3d3e-421f-a9b9-aaba8c7a66b2"
      },
      "cell_type": "code",
      "source": [
        "scores = model.evaluate(X_test, Y_test, verbose = 10 )\n",
        "print ( scores )"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.8265708412442888, 0.8071428571428572]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}